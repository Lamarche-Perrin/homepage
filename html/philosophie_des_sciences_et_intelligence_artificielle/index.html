<!-- 
	 This file is part of Robin Lamarche-Perrin's personal web site
	 (mail: <Robin.Lamarche-Perrin@lip6.fr>).

	 This web site and all its content is licensed under a Creative
	 Commons Attribution Share-a-like 4.0 International License.
	 
	 You should have received a copy of this license with these
	 files. If not, see <http://creativecommons.org/licenses/by-sa/4.0/>
	 and <https://creativecommons.org/licenses/by-sa/4.0/legalcode>.
  -->

<link rel="stylesheet" type="text/css" href="css/style.css" media="screen">
<html>
  <head>
	<title>Philosophie des sciences et intelligence artificielle</title>
	<meta charset="UTF-8">
	<style type="text/css">
	  #wrap { text-align: justify; font-size:105%; width:100%; }
	  #left_col { float:left; width:55%; margin:20px; }
	  #right_col { float:left; width:35%; margin:20px; }
	</style>
  </head>
  
  <body>

	<div id="wrap">
	  <center><h1>Journée &laquo;&nbsp;Philosophie des sciences et intelligence artificielle&nbsp;&raquo;</h1></center>
	  <div id="left_col">
		<hr>
		
		<h3>L'IA comme épistémologie expérimentale&nbsp;: regards sur 40 ans d'histoire</h3>
		Par <b>Joël Quinqueton</b>,
		Professeur émérite de l'Université de Montpellier III, Laboratoire d'Informatique, de Robotique et de Microélectronique de Montpellier<br>
		<a href='./SPS-AFIA-Quinqueton.pdf' target='_blank'>Télécharger la présentation</a><br><br>

		En 40 ans, l'Intelligence Artificielle est passée du statut de curiosité futuriste pour informaticiens à celui d'être artificiel pensant dont les performances suscitent parfois la crainte. Elle apparaît assez naturellement comme susceptible de mettre en &oelig;uvre une démarche épistémologique, mais l'a-t-elle vraiment fait, et comment&nbsp;? Après 40 ans d'observation active de domaines comme l'apprentissage automatique et plus généralement le raisonnement sur ce qui est plausible ou vraisemblable, je m'efforcerai de proposer quelques éléments de réponse.<br><br>

		<hr>

		<h3>GOFAI, NEWFAI et le problème de l'intentionnalisme</h3>
		Par <b>Jean-Michel Roy</b>,
		Professeur à l'École normale supérieure de Lyon et à l'École normale supérieure de l'Est de la Chine<br><br>

		La Good Old Fashion Artificial Intelligence, légitimement considérée comme une application des principes généraux de la conception cognitiviste de la cognition, s'est heurtée à diverses limitations désormais bien établies et renvoyant à un certain nombre de problèmes de fondements autour desquels s'est cristallisé le débat philosophique contemporain sur l'intelligence artificielle. Parmi eux figure au premier chef celui de la capacité de cette dernière à artificialiser la propriété d'intentionnalité considérée par la majorité des théories des facultés mentales depuis le dernier quart du XIX siècle (cf. en particulier Franz Brentano 1874), y compris celles issues de la Révolution Cognitive des années 50, comme une marque essentielle du mental. Les plus célèbres arguments critiques déployés à cet effet sont ceux de Hubert Dreyfus et de John Searle. Ils jouèrent un rôle actif dans le processus d'émergence de ladite Newfound Artificial Intelligence, autour de laquelle s'est progressivement ralliée une grande partie du domaine de l'intelligence artificielle. Cette évolution cruciale d'une approche GOFAI à une approche NEWFAI peut être considérée comme une facette particulière de la transformation plus générale de ses principes fondamentaux qu'a connue l'entreprise cognitive contemporaine, et qui l'a conduite du cognitivisme à la perspective désormais couramment dénommée 4E. La question se pose donc de savoir si, et le cas échéant comment et avec quel succès, l'approche NEWFAI, et partant d'une certaine manière l'approche 4E dans laquelle elle s'inscrit, a résolu le problème de l'artificialisation de l'intentionnalité. Telle est celle qui sera examinée ici.<br><br>

		<hr>

		<h3>Le rôle de la complexité et de la simplicité dans l'émergence des capacités cognitives</h3>
		Par <b>Jean-Louis Dessalles</b>, 
		Professeur à Télécom ParisTech, Université Paris-Saclay, Laboratoire Traitement et Communication de l'Information<br>
		<a href='./SPS-AFIA-Dessalles.pdf' target='_blank'>Télécharger la présentation</a><br><br>

		Les espèces animales se distinguent les unes des autres par des caractéristiques remarquables. Notre cognition fait certainement de nous des primates atypiques. Peut-on caractériser ce que nous appelons notre intelligence, et comment se fait-il qu'elle ait émergé dans notre lignée&nbsp;? Turing a défini l'intelligence comme la capacité à être pertinent dans le dialogue. La pertinence est une exigence forte que nous imposons à nos congénères pour établir des liens sociaux. Ceux qui ne sont pas pertinents sont ignorés, voire exclus. Je montrerai comment les notions de complexité et de simplicité permettent de cerner la notion de pertinence, en ouvrant la voie vers sa reproduction par des machines. Cette démarche permet de poser en des termes nouveaux la question : pourquoi sommes-nous dotés de cette forme si particulière de cognition&nbsp;?<br><br>

		<hr>

		<h3>D'une intelligence artificielle à une intelligence incarnée dans l'activité humaine</h3>
		Par <b>Catherine Garbay</b>,
		Directrice de recherche au CNRS, Laboratoire d'Informatique de Grenoble<br>
		<a href='./SPS-AFIA-Garbay.pdf' target='_blank'>Télécharger la présentation</a><br><br>

		Mon point focal pour cet exposé est celui de la constitutivité technique de la cognition. Au-delà du couplage entre l'instrument et l'activité humaine, je souhaite questionner comment l'expérience humaine, l'histoire singulière du sujet, se développent et se construisent dans l'activité médiée par un instrument. Au plan technique, je propose comme champ d'analyse celui de l'intelligence ambiante. Il s'agit d'une classe d'instrument particulière, susceptible d'apporter un éclairage pertinent et une forme de renouveau à ces questions, en raison de ses relations étroites au champ de l'Intelligence Artificielle et de ses développements technologiques très récents. A partir d'un rappel des propriétés principales de cet instrument, je me propose d'interroger les formes de couplage humain-technique qu'il engendre, ses limites et ses évolutions. La &laquo;&nbsp;qualité de l'expérience humaine&nbsp;&raquo; est ici analysée sous l'angle de plusieurs propriétés, comme le rapport au réel, l'autonomie, ou la construction du sens. À partir de ces constats, j'évoquerai quelques lignes d'évolution de ce champ scientifique qui me semblent importantes dans la perspective d'un meilleur couplage entre l'instrument et l'expérience singulière de l'humain.<br><br>

		<hr>

		<h3>Intelligence artificielle et &laquo;&nbsp;cognition 4E&nbsp;&raquo;&nbsp;: un changement de paradigme&nbsp;?</h3>
		Par <b>Pierre Steiner</b>,
		Enseignant-chercheur à l'Université de technologie de Compiègne, Laboratoire Connaissances, Organisations et Systèmes Technique<br>
		<a href='./SPS-AFIA-Steiner.pdf' target='_blank'>Télécharger la présentation</a><br><br>

		Quelle est la pertinence et quelles sont les limites du concept de &laquo;&nbsp;paradigme&nbsp;&raquo;, fréquemment mobilisé aujourd'hui pour décrire les transformations contemporaines des sciences cognitives et de l'intelligence artificielle&nbsp;? Qu'il s'agisse d'un proto-paradigme ou d'un ensemble de programmes de recherche hétérogènes, qu'est-ce que la &laquo;&nbsp;cognition 4E&nbsp;&raquo;&nbsp;? Je répondrai à ces questions en insistant notamment sur la diversité des conceptions de l'embodiment que l'on peut retrouver au sein de cette nébuleuse &laquo;&nbsp;4E&nbsp;&raquo;, avant d'aborder la question suivante&nbsp;: une prise en compte des dimensions &laquo;&nbsp;incarnées&nbsp;&raquo;, &laquo;&nbsp;situées&nbsp;&raquo;, &laquo;&nbsp;étendues&nbsp;&raquo; et &laquo;&nbsp;énactives&nbsp;&raquo; de la cognition est-elle nécessaire et/ou suffisante pour passer d'un ancien paradigme à un nouveau paradigme en IA, ou pour assister à des transformations au sein d'un paradigme déjà existant&nbsp;? Si l'on souhaite s'interroger sur les conséquences éventuelles de la cognition 4E sur l'IA contemporaine, il convient aussi de remarquer l'influence d'une certaine IA sur les prémisses théoriques de la cognition 4E. Une inspiration importante des travaux précurseurs de Fr. Varela (1991), J. Haugeland (1995) ou R. McClamrock (1995) fut en effet un ensemble de réalisations en IA (Brooks, Agre et Chapman, Winograd et Flores, Ballard…), réalisations qui étaient déjà interprétées par ces auteurs comme exemplifiant les traits majeurs de ce qui deviendra la &laquo;&nbsp;cognition 4E&nbsp;&raquo;. Je terminerai en m'intéressant aux critiques qu'Hubert Dreyfus a pu récemment adresser à certains défenseurs d'une cognition &laquo;&nbsp;4E&nbsp;&raquo; appliquée à l'IA, en identifiant une – voire la – tension majeure au sein de la nébuleuse &laquo;&nbsp;4E&nbsp;&raquo; actuelle, y compris en IA : le statut du représentationnalisme, même lorsqu'il est non-symbolique et minimal.<br><br>


		<hr>

		<h3>Questionnements éthiques sur la Robotique et l'Intelligence Artificielle</h3>
		Par <b>Raja Chatila</b>,
		Professeur à l'Université Pierre-et-Marie-Curie, directeur de l'Institut des Systèmes Intelligents et de Robotique<br>
		<a href='./SPS-AFIA-Chatila.pdf' target='_blank'>Télécharger la présentation</a><br><br>

		Les questionnements sur les problèmes éthiques, légaux et sociétaux (dits ELS) posés par le développement de l'Intelligence Artificielle et de la robotique datent d'une quinzaine d'années (même si quelques réflexions avaient déjà débuté auparavant) et sont devenus dernièrement assez prégnants, avec l'apparition de nouvelles applications. Ils concernent des sujets très variés tels que l'emploi, la protection de la vie privée et l'exploitation des données personnelles, la surveillance, l'interaction avec des personnes vulnérables, la dignité humaine, la prise de décision autonome, la responsabilité morale et juridique du robot ou du système intelligent, l'imitation du vivant, le statut du robot dans la société, le statut de l'humain augmenté par le robot (voir <a href='http://cerna-ethics-allistene.org/digitalAssets/38/38704_Avis_robotique_livret.pdf' target='_blank'>rapport de la CERNA en 2014</a>). La démarche de recherche et de conception elle-même est en cause : comment développer des systèmes avec une méthodologie éthique et responsable&nbsp;? Est-il possible de réaliser des systèmes qui incluent dans leur propre fonctionnement et dans leurs prises de décisions autonomes des valeurs humaines&nbsp;?

		Ces questionnements renouvellent parfois des sujets classiques en philosophie éthique et en matière de droit en les transposant aux machines, mais posent aussi des problématiques nouvelles sur lesquels la réflexion doit mobiliser des communautés interdisciplinaires pour permettre d'appréhender l'ensemble des facettes scientifiques, techniques, humaines et sociales.

	  </div>
	  
      <div id="right_col">
		<img src='visuel.jpg' width=90%><br>

		<hr>
		
		Journée de séminaire organisée le jeudi 2 février 2017, à l'École normale supérieure, par&nbsp;:
		<ul>
		  <li>l'<a href='http://www.afia.asso.fr/' target='_blank'>Association française pour l'intelligence artificielle</a>,</li>
		  <li>la <a href='http://www.sps-philoscience.org/' target='_blank'>Société de philosophie des sciences</a>,</li>
		  <li>le <a href='http://www.cognition.ens.fr/' target='_blank'>Département d'étude cognitive</a> de l'École normale supérieure</li>
		</ul>

		Responsables scientifiques&nbsp;:
		<ul>
		  <li><a href='https://www-complexnetworks.lip6.fr/~lamarche/' target='_blank'>Robin Lamarche-Perrin</a> (CNRS, ISC-PIF, LIP6)</li>
		  <li><a href='http://andler.dec.ens.fr/' target='_blank'>Daniel Andler</a> (ENS, DEC)</li>
		</ul>
		
		Chargée de dissémination scientifique&nbsp;:
		<ul>
		  <li>Clémentine Eyraud (IEC, DEC)</li>
		</ul>

		<!--
			Page Web
			https://www.eventbrite.fr/e/inscription-journee-philosophie-des-sciences-et-intelligence-artificielle-30888523405
		  -->	

		<hr>

		<h3>Thématiques de la journée</h3>

		Dès son apparition dans les années 1950, l'intelligence artificielle (IA) a suscité une intense curiosité chez les philosophes. Soixante ans plus tard, après avoir traversé des périodes difficiles, mais également contribué à l'essor des sciences cognitives, l'IA semble aujourd'hui en passe de remplir ses promesses et d'introduire une série de bouleversements économiques, culturels, voire anthropologiques. Mais l'IA d'aujourd'hui est-elle celle d'hier&nbsp;? Qu'annoncent ses succès présents&nbsp;? Pour commencer à répondre à ces questions, une réévaluation de ses fondements et de sa place dans le système technoscientifique semble nécessaire. À cette tâche, qui échoit à parts égales aux spécialistes du domaine et aux philosophes des sciences, l'AFIA, la SPS, et le DEC ont souhaité contribuer en organisant une journée d'étude, focalisée sur trois thèmes complémentaires&nbsp;:
		<ul>
		  <li>la philosophie de l'IA et l'IA comme philosophie expérimentale&nbsp;;</li>
		  <li>l'impact du tournant pragmatique pour l'IA, et en particulier les approches 4EA (Embodied, Embedded, Enacted, Extended, Affective)&nbsp;;</li>
		  <li>l'apport des concepts d'émergence et de complexité dans notre compréhension de ce que sont l'intelligence et la cognition.</li>
		</ul>

		<!--
			Programme

			8:30-9:00	Accueil des participants

			9:00-9:30	Présentation de l'AFIA (Yves Demazeau), de la SPS (Stéphanie Ruphy) et du DEC (Daniel Andler)

			9:30-10:20	Joël Quinqueton, L'IA comme épistémologie expérimentale&nbsp;: regards sur 40 ans d'histoire
			Professeur émérite de l'Université de Montpellier III, Laboratoire d'Informatique, de Robotique et de Microélectronique de Montpellier

			10:20-10:40	Pause

			10:40-11:30	Jean-Michel Roy, GOFAI, NEWFAI et le problème de l'intentionnalisme
			Professeur à l'École normale supérieure de Lyon et à l'École normale supérieure de l'Est de la Chine

			11:30-12:20	Jean-Louis Dessalles, Le rôle de la complexité et de la simplicité dans l'émergence des capacités cognitives
			Professeur à Télécom ParisTech, Laboratoire Traitement et Communication de l'Information

			12:20-13:40	Repas (offert par l'AFIA, la SPS et le DEC)

			13:40-14:30	Catherine Garbay, D'une intelligence artificielle à une intelligence incarnée dans l'activité humaine
			Directrice de recherche au CNRS, Laboratoire d'Informatique de Grenoble

			14:30-15:20	Pierre Steiner, Intelligence artificielle et &laquo;&nbsp;cognition 4E&nbsp;&raquo;&nbsp;: un changement de paradigme&nbsp;?
			Enseignant-chercheur à l'Université de technologie de Compiègne, Laboratoire Connaissances, Organisations et Systèmes Technique

			15:20-15:40	Pause

			15:40-16:30	Raja Chatila, Questionnements éthiques sur la Robotique et l'Intelligence Artificielle
			Professeur à l'Université Pierre-et-Marie-Curie, directeur de l'Institut des Systèmes Intelligents et de Robotique

			16:30-17:20	Daniel Andler, discussion et clôture de la journée
			Professeur émérite de l'université Paris-Sorbonne, membre de l'Académie des sciences morales et politiques
		  -->

		<hr>
		
		<img src='logos.jpg' width=90%>

      </div>
	  
	</div>

  </body>
</html>
